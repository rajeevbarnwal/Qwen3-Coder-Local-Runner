name: CI â€“ Run Qwen3-Coder

on:
  push:
    branches: [ main ]
    paths:
      - 'scripts/llama_cpp_setup.sh'
      - 'scripts/run_qwen.sh'
      - 'scripts/model_download.py'
      - 'scripts/tool_calling_example.py'
      - 'Dockerfile'
      - '.github/workflows/run_qwen.yml'
  workflow_dispatch: {}

jobs:
  build-and-run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Cache llama.cpp build
        uses: actions/cache@v3
        with:
          # caches the build directory so recompilation is skipped if unchanged
          path: llama.cpp/build
          key: ${{ runner.os }}-llama-build-${{ hashFiles('scripts/llama_cpp_setup.sh') }}

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Python deps
        run: |
          pip install --upgrade pip
          pip install huggingface_hub hf_transfer transformers

      - name: Download Qwen3 model
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: python scripts/model_download.py

      - name: Build llama.cpp
        run: bash scripts/llama_cpp_setup.sh

      - name: Run Qwen inference script
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: bash scripts/run_qwen.sh

